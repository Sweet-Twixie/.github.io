---
layout: default
title: Feature Selection
---

# Feature Selection âš¡

Feature selection was a key step in the project to identify the most predictive skills for classifying football players into general categories: **Defender, Midfielder, Forwarder**. This ensures the model focuses on the features that matter most, improving performance and interpretability.

## ðŸ”¹ Initial Feature Set
We started with a comprehensive set of engineered features representing player skills, physical attributes, and mentality metrics, including:

- Attacking: crossing, finishing, heading accuracy, short passing, volleys  
- Skill: dribbling, curve, long passing, ball control  
- Movement: acceleration, sprint speed, agility, balance  
- Power: shot power, jumping, stamina, strength  
- Mentality: vision, interceptions, positioning  
- Pace and shooting metrics (standardized or transformed)  

A total of **40+ features** were included in the cleaned dataset.

## ðŸ”¹ Target Categories
The model predicts **general player roles**:

- Defender  
- Midfielder  
- Forwarder  

### Subcategories (used in further modeling)
- CB, RB, LB, CDM, CM, LM, RM, CAM, ST, LW, RW, CF, RWB, LWB  

---

## ðŸ”¹ Feature Selection Methods
We applied three complementary approaches to determine which features were most important for classification:

1. **Random Forest Feature Importance**  
   - Trained a Random Forest classifier on the dataset.  
   - Ranked features by importance and selected the top 10.  

2. **Recursive Feature Elimination (RFE)**  
   - Used RFE with a Random Forest estimator to iteratively select the most relevant features.  
   - Chose 10 features that consistently contributed to accurate predictions.  

3. **Gradient Boosting Feature Importance**  
   - Trained a Gradient Boosting classifier.  
   - Selected the top 10 features by importance score.  

**Selected features from each method:**

Random Forest Selected Features: [list rf_selected_features here]
RFE Selected Features: [list rfe_selected_features here]
Gradient Boosting Selected Features: [list gb_selected_features here]

---

## ðŸ”¹ Final Selected Features

After comparing the outputs of **Random Forest**, **RFE**, and **Gradient Boosting**, and cross-checking with correlation analysis, I finalized a set of **10 key features** that consistently showed strong predictive power across methods:

- `attacking_heading_accuracy_standardized`  
- `attacking_short_passing_standardized`  
- `skill_long_passing_standardized`  
- `power_strength_standardized`  
- `defending_average`  
- `defending_category_encoded`  
- `shooting_standardize`  
- `mentality_interceptions_categories_encoded`  
- `dribbling_standardize`  
- `mentality_positioning_categories_encoded`  

âœ… These features represent a **balanced mix of attacking, defending, physical, and mentality attributes**, making them highly informative for distinguishing between **Defenders, Midfielders, and Forwarders**.  

---

## ðŸ”¹ Feature Selection Code Example
---
layout: default
title: Feature Selection
---

# Feature Selection âš¡

Feature selection was a key step in the project to identify the most predictive skills for classifying football players into general categories (**Defender, Midfielder, Forwarder**) and into their **specific positions**.  
By reducing the dimensionality of the dataset, the models could focus on the features that matter most, improving both **performance** and **interpretability**.

---

## ðŸ”¹ Initial Feature Set
We started with a comprehensive set of engineered features representing player skills, physical attributes, and mentality metrics, including:

- **Attacking**: crossing, finishing, heading accuracy, short passing, volleys  
- **Skill**: dribbling, curve, long passing, ball control  
- **Movement**: acceleration, sprint speed, agility, balance  
- **Power**: shot power, jumping, stamina, strength  
- **Mentality**: vision, interceptions, positioning  
- **Pace & Shooting metrics** (standardized or transformed)  

A total of **40+ features** were included in the cleaned dataset.

---

## ðŸ”¹ General Category Selection
To classify players into **Defender, Midfielder, Forwarder**, three complementary feature selection methods were applied:

1. **Random Forest Feature Importance** â†’ Ranked features by importance.  
2. **Recursive Feature Elimination (RFE)** â†’ Iteratively removed least important features until the optimal subset was found.  
3. **Gradient Boosting Feature Importance** â†’ Validated feature relevance through boosting models.  

### âœ… Final Selected Features (for general classification)
After comparing the results, I finalized a set of **10 features** that consistently showed strong predictive power:

- `attacking_heading_accuracy_standardized`  
- `attacking_short_passing_standardized`  
- `skill_long_passing_standardized`  
- `power_strength_standardized`  
- `defending_average`  
- `defending_category_encoded`  
- `shooting_standardize`  
- `mentality_interceptions_categories_encoded`  
- `dribbling_standardize`  
- `mentality_positioning_categories_encoded`  

These features represent a balanced mix of **attacking, defending, physical, and mentality skills**, making them highly informative for separating Defenders, Midfielders, and Forwarders.

---

## ðŸ”¹ Category-Specific Feature Selection
In addition to general classification, I performed **feature selection separately for each category** (**Defender, Midfielder, Forwarder**) because each role requires different skill sets.  

For each subset, I applied **Random Forest Feature Importance** to select the **top 10 most relevant features** that best predict the specific positions within that category.

### Example: Forwarder Feature Selection
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import pandas as pd

X_forwarder = df_forwarder.drop(['ST', 'LW', 'RW', 'CF', 'LWB', 'RWB'], axis=1)
y_forwarder = df_forwarder[['ST', 'LW', 'RW', 'CF', 'LWB', 'RWB']]

y_forwarder_encoded = LabelEncoder().fit_transform(y_forwarder.values.argmax(axis=1))

X_train, X_test, y_train, y_test = train_test_split(X_forwarder, y_forwarder_encoded,
                                                    test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

rf_feature_importance = pd.Series(rf_model.feature_importances_, index=X_train.columns)
rf_selected_features = rf_feature_importance.sort_values(ascending=False).head(10)

print("Random Forest Selected Features:\n", rf_selected_features)

```

